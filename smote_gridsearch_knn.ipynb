{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a06a5ef",
   "metadata": {},
   "source": [
    "# SMOTE + GridSearch + KNN - Stress Level Detection\n",
    "\n",
    "Implementasi KNN dengan kombinasi SMOTE untuk mengatasi ketidakseimbangan kelas dan GridSearchCV untuk optimasi hyperparameter dalam klasifikasi tingkat stress.\n",
    "\n",
    "**Skenario**: SMOTE + GridSearch + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e99569",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade imbalanced-learn\n",
    "!pip install --upgrade scikit-learn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import time\n",
    "\n",
    "print(\"✅ Library berhasil diimport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ceb1a",
   "metadata": {},
   "source": [
    "## 1. Data Loading dan Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = './dataset/fix dataset 1031.csv'\n",
    "\n",
    "# Read CSV with semicolon as separator and handle mixed decimal separators\n",
    "df = pd.read_csv(FILE_PATH, sep=';', decimal='.')\n",
    "dataset = df.copy()\n",
    "\n",
    "# Tampilkan Semua row pada kolom pertama yang memiliki nilai NaN\n",
    "print(\"📊 DATASET INFORMATION:\")\n",
    "print(\"Jumlah baris yang memiliki nilai NaN pada kolom pertama:\", dataset[dataset.columns[0]].isna().sum())\n",
    "\n",
    "# Bersihkan data dengan menghapus baris yang memiliki nilai NaN pada kolom pertama\n",
    "dataset = dataset.dropna(subset=[dataset.columns[0]])\n",
    "\n",
    "print(\"Dataset shape:\", dataset.shape)\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Sleep Disorder with 'Normal'\n",
    "dataset['Sleep Disorder'] = dataset['Sleep Disorder'].fillna('Normal')\n",
    "\n",
    "# Split Blood Pressure column\n",
    "if 'Blood Pressure' in dataset.columns:\n",
    "    dataset[['Systolic', 'Diastolic']] = dataset['Blood Pressure'].str.split('/', expand=True)\n",
    "    dataset['Systolic'] = pd.to_numeric(dataset['Systolic'], errors='coerce')\n",
    "    dataset['Diastolic'] = pd.to_numeric(dataset['Diastolic'], errors='coerce')\n",
    "    dataset = dataset.drop('Blood Pressure', axis=1)\n",
    "\n",
    "# Clean numeric columns\n",
    "kolom_numerik = [\"Sleep Duration\", \"Heart Rate\", \"Daily Steps\", \"Systolic\", \"Diastolic\"]\n",
    "for col in kolom_numerik:\n",
    "    if col in dataset.columns:\n",
    "        dataset[col] = dataset[col].apply(lambda x: str(x).replace(',', '.') if isinstance(x, str) else x)\n",
    "        dataset[col] = pd.to_numeric(dataset[col], errors='coerce')\n",
    "\n",
    "print(\"✅ Data preprocessing selesai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07478d",
   "metadata": {},
   "source": [
    "## 2. Target Encoding dan Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for target\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(dataset['Sleep Disorder'])\n",
    "\n",
    "print(\"Target classes:\", label_encoder.classes_)\n",
    "print(\"Encoded values:\", np.unique(target_encoded))\n",
    "\n",
    "# Show class distribution BEFORE SMOTE\n",
    "print(\"\\n=== DISTRIBUSI KELAS BEFORE SMOTE ====\")\n",
    "class_counts_before = pd.Series(target_encoded).value_counts().sort_index()\n",
    "for i, count in enumerate(class_counts_before):\n",
    "    print(f\"{label_encoder.classes_[i]}: {count} samples\")\n",
    "\n",
    "total_before = len(target_encoded)\n",
    "print(f\"\\nTotal samples before SMOTE: {total_before}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "feature_columns = [\"Gender\", \"Age\", \"Occupation\", \"Sleep Duration\", \"Quality of Sleep\", \n",
    "                  \"Physical Activity Level\", \"Stress Level\", \"BMI Category\", \"Systolic\", \"Diastolic\"]\n",
    "\n",
    "# Filter only existing columns\n",
    "available_features = [col for col in feature_columns if col in dataset.columns]\n",
    "features = dataset[available_features]\n",
    "\n",
    "print(\"Selected features:\", available_features)\n",
    "print(\"Features shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44856e11",
   "metadata": {},
   "source": [
    "## 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929fb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target_encoded, test_size=0.2, random_state=42, stratify=target_encoded\n",
    ")\n",
    "\n",
    "print(\"=== DATA SPLIT ====\")\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "print(\"\\nDistribusi y_train BEFORE SMOTE:\")\n",
    "train_dist_before = pd.Series(y_train).value_counts().sort_index()\n",
    "for i, count in enumerate(train_dist_before):\n",
    "    print(f\"{label_encoder.classes_[i]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff1f4df",
   "metadata": {},
   "source": [
    "## 4. Pipeline Setup dengan SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de3e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "numerical_features = [col for col in available_features if features[col].dtype in ['int64', 'float64']]\n",
    "categorical_features = [col for col in available_features if features[col].dtype == 'object']\n",
    "\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Create preprocessors\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "print(\"✅ Preprocessor pipeline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a3b20",
   "metadata": {},
   "source": [
    "## 5. SMOTE Application untuk Melihat Efek Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e398ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to see the effect of SMOTE clearly\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "print(\"=== COMPARISON BEFORE vs AFTER SMOTE ====\")\n",
    "print(\"\\nBEFORE SMOTE:\")\n",
    "for i, count in enumerate(train_dist_before):\n",
    "    print(f\"{label_encoder.classes_[i]}: {count} samples\")\n",
    "print(f\"Total: {len(y_train)} samples\")\n",
    "\n",
    "print(\"\\nAFTER SMOTE:\")\n",
    "train_dist_after = pd.Series(y_train_smote).value_counts().sort_index()\n",
    "for i, count in enumerate(train_dist_after):\n",
    "    print(f\"{label_encoder.classes_[i]}: {count} samples\")\n",
    "print(f\"Total: {len(y_train_smote)} samples\")\n",
    "\n",
    "# Calculate increase\n",
    "print(\"\\nINCREASE PER CLASS:\")\n",
    "for i in range(len(label_encoder.classes_)):\n",
    "    before = train_dist_before.iloc[i] if i < len(train_dist_before) else 0\n",
    "    after = train_dist_after.iloc[i] if i < len(train_dist_after) else 0\n",
    "    increase = after - before\n",
    "    print(f\"{label_encoder.classes_[i]}: +{increase} samples (from {before} to {after})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution before and after SMOTE\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Before SMOTE\n",
    "before_data = pd.DataFrame({\n",
    "    'Class': [label_encoder.classes_[i] for i in train_dist_before.index],\n",
    "    'Count': train_dist_before.values\n",
    "})\n",
    "sns.barplot(data=before_data, x='Class', y='Count', ax=ax1)\n",
    "ax1.set_title('Class Distribution BEFORE SMOTE')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# After SMOTE\n",
    "after_data = pd.DataFrame({\n",
    "    'Class': [label_encoder.classes_[i] for i in train_dist_after.index],\n",
    "    'Count': train_dist_after.values\n",
    "})\n",
    "sns.barplot(data=after_data, x='Class', y='Count', ax=ax2)\n",
    "ax2.set_title('Class Distribution AFTER SMOTE')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d64f8",
   "metadata": {},
   "source": [
    "## 6. Baseline Model (Before GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline SMOTE + KNN pipeline (default parameters)\n",
    "baseline_smote_pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Train baseline model\n",
    "print(\"Training baseline SMOTE + KNN model...\")\n",
    "baseline_smote_pipeline.fit(X_train, y_train)\n",
    "baseline_pred = baseline_smote_pipeline.predict(X_test)\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "\n",
    "print(\"=== BASELINE MODEL (BEFORE GridSearch) ====\")\n",
    "print(\"Default hyperparameters:\")\n",
    "knn_params = baseline_smote_pipeline.named_steps['knn'].get_params()\n",
    "important_params = ['n_neighbors', 'weights', 'algorithm', 'metric', 'p']\n",
    "for param in important_params:\n",
    "    if param in knn_params:\n",
    "        print(f\"  {param}: {knn_params[param]}\")\n",
    "\n",
    "print(f\"\\nBaseline accuracy with SMOTE: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da9f66",
   "metadata": {},
   "source": [
    "## 7. GridSearchCV untuk Optimasi Hyperparameter dengan SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'knn__p': [1, 2]  # Only relevant for minkowski metric\n",
    "}\n",
    "\n",
    "print(\"Parameter grid for GridSearch dengan SMOTE:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "print(f\"\\nTotal combinations to test: {np.prod([len(v) for v in param_grid.values()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd7d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for GridSearch with SMOTE\n",
    "grid_smote_pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Perform GridSearchCV\n",
    "print(\"Starting GridSearchCV with SMOTE + KNN...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search_smote = GridSearchCV(\n",
    "    grid_smote_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,  # Sequential processing (avoids pickling issues with ImbPipeline)\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_smote.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n✅ GridSearchCV dengan SMOTE completed in {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de69009e",
   "metadata": {},
   "source": [
    "## 8. GridSearch Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display GridSearch results\n",
    "print(\"=== GRIDSEARCH + SMOTE RESULTS ====\")\n",
    "print(\"\\nBest parameters found:\")\n",
    "for param, value in grid_search_smote.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest cross-validation score: {grid_search_smote.best_score_:.4f} ({grid_search_smote.best_score_*100:.2f}%)\")\n",
    "\n",
    "# Test the best model\n",
    "best_model_smote = grid_search_smote.best_estimator_\n",
    "y_pred_grid_smote = best_model_smote.predict(X_test)\n",
    "grid_smote_accuracy = accuracy_score(y_test, y_pred_grid_smote)\n",
    "\n",
    "print(f\"Test set accuracy with best SMOTE + GridSearch model: {grid_smote_accuracy:.4f} ({grid_smote_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b80afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Before vs After GridSearch (both with SMOTE)\n",
    "print(\"=== COMPARISON: BEFORE vs AFTER GridSearch (dengan SMOTE) ====\")\n",
    "print(\"\\nBEFORE GridSearch (SMOTE + default KNN parameters):\")\n",
    "print(f\"  n_neighbors: 5\")\n",
    "print(f\"  weights: uniform\")\n",
    "print(f\"  algorithm: auto\")\n",
    "print(f\"  metric: minkowski\")\n",
    "print(f\"  p: 2\")\n",
    "print(f\"  Accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nAFTER GridSearch (SMOTE + optimized KNN parameters):\")\n",
    "for param, value in grid_search_smote.best_params_.items():\n",
    "    param_name = param.replace('knn__', '')\n",
    "    print(f\"  {param_name}: {value}\")\n",
    "print(f\"  Accuracy: {grid_smote_accuracy:.4f} ({grid_smote_accuracy*100:.2f}%)\")\n",
    "\n",
    "improvement = grid_smote_accuracy - baseline_accuracy\n",
    "print(f\"\\nImprovement: {improvement:.4f} ({improvement*100:.2f} percentage points)\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"✅ GridSearch improved SMOTE + KNN model performance!\")\n",
    "elif improvement == 0:\n",
    "    print(\"➖ No improvement from GridSearch\")\n",
    "else:\n",
    "    print(\"⚠️ GridSearch resulted in lower performance (may indicate overfitting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b6f21",
   "metadata": {},
   "source": [
    "## 9. Detailed Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35457289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"=== DETAILED PERFORMANCE ANALYSIS ====\")\n",
    "print(\"\\nClassification Report (Best SMOTE + GridSearch Model):\")\n",
    "print(classification_report(y_test, y_pred_grid_smote, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcec87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_grid_smote = confusion_matrix(y_test, y_pred_grid_smote)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_grid_smote, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix - SMOTE + GridSearch + KNN\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc21088",
   "metadata": {},
   "source": [
    "## 10. Comparison dengan Model Lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2cb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN murni untuk comparison\n",
    "knn_murni = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_murni.fit(X_train, y_train)\n",
    "pred_murni = knn_murni.predict(X_test)\n",
    "accuracy_murni = accuracy_score(y_test, pred_murni)\n",
    "\n",
    "# Train KNN + SMOTE tanpa GridSearch\n",
    "knn_smote_only = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "knn_smote_only.fit(X_train, y_train)\n",
    "pred_smote_only = knn_smote_only.predict(X_test)\n",
    "accuracy_smote_only = accuracy_score(y_test, pred_smote_only)\n",
    "\n",
    "print(\"=== COMPARISON: SEMUA MODEL ====\")\n",
    "print(f\"1. KNN Murni: {accuracy_murni:.4f} ({accuracy_murni*100:.2f}%)\")\n",
    "print(f\"2. KNN + SMOTE: {accuracy_smote_only:.4f} ({accuracy_smote_only*100:.2f}%)\")\n",
    "print(f\"3. SMOTE + GridSearch + KNN: {grid_smote_accuracy:.4f} ({grid_smote_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nImprovement SMOTE vs Murni: {(accuracy_smote_only - accuracy_murni)*100:+.2f} pp\")\n",
    "print(f\"Improvement SMOTE+GridSearch vs Murni: {(grid_smote_accuracy - accuracy_murni)*100:+.2f} pp\")\n",
    "print(f\"Improvement SMOTE+GridSearch vs SMOTE: {(grid_smote_accuracy - accuracy_smote_only)*100:+.2f} pp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "models = ['KNN Murni', 'KNN + SMOTE', 'SMOTE + GridSearch + KNN']\n",
    "accuracies = [accuracy_murni, accuracy_smote_only, grid_smote_accuracy]\n",
    "colors = ['lightblue', 'orange', 'darkgreen']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models, accuracies, color=colors, alpha=0.7)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11e559",
   "metadata": {},
   "source": [
    "## 11. Top 10 Best Parameter Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba541ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 10 parameter combinations\n",
    "results_df = pd.DataFrame(grid_search_smote.cv_results_)\n",
    "top_10 = results_df.nlargest(10, 'mean_test_score')[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "print(\"=== TOP 10 PARAMETER COMBINATIONS (SMOTE + GridSearch) ====\")\n",
    "for i, (idx, row) in enumerate(top_10.iterrows(), 1):\n",
    "    print(f\"\\n{i}. Score: {row['mean_test_score']:.4f} (±{row['std_test_score']:.4f})\")\n",
    "    print(f\"   Parameters: {row['params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f7ccf7",
   "metadata": {},
   "source": [
    "## 12. K Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the effect of different k values specifically\n",
    "k_values = param_grid['knn__n_neighbors']\n",
    "k_scores = []\n",
    "\n",
    "# Filter results for the best other parameters but varying k\n",
    "best_params_except_k = {k: v for k, v in grid_search_smote.best_params_.items() if k != 'knn__n_neighbors'}\n",
    "\n",
    "for k in k_values:\n",
    "    # Find results with this k and best other parameters\n",
    "    matching_rows = results_df[\n",
    "        (results_df['param_knn__n_neighbors'] == k) &\n",
    "        (results_df['param_knn__weights'] == best_params_except_k.get('knn__weights')) &\n",
    "        (results_df['param_knn__algorithm'] == best_params_except_k.get('knn__algorithm')) &\n",
    "        (results_df['param_knn__metric'] == best_params_except_k.get('knn__metric')) &\n",
    "        (results_df['param_knn__p'] == best_params_except_k.get('knn__p'))\n",
    "    ]\n",
    "    \n",
    "    if not matching_rows.empty:\n",
    "        k_scores.append(matching_rows['mean_test_score'].iloc[0])\n",
    "    else:\n",
    "        k_scores.append(0)\n",
    "\n",
    "# Plot k vs accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, k_scores, marker='o', linewidth=2, markersize=6, color='green')\n",
    "best_k = grid_search_smote.best_params_['knn__n_neighbors']\n",
    "plt.axvline(x=best_k, color='red', linestyle='--', alpha=0.7, label=f'Best k={best_k}')\n",
    "plt.title('Cross-Validation Accuracy vs. Number of Neighbors (k) - SMOTE + GridSearch')\n",
    "plt.xlabel('k (Number of Neighbors)')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.xticks(k_values)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== K OPTIMAL untuk SMOTE + GridSearch + KNN ====\")\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(f\"Best CV score with k={best_k}: {grid_search_smote.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b439ff9f",
   "metadata": {},
   "source": [
    "## 13. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FINAL SUMMARY - SMOTE + GRIDSEARCH + KNN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📊 DATASET INFORMATION:\")\n",
    "print(f\"   Total samples: {len(dataset)}\")\n",
    "print(f\"   Features used: {len(available_features)}\")\n",
    "print(f\"   Classes: {len(label_encoder.classes_)} ({', '.join(label_encoder.classes_)})\")\n",
    "\n",
    "print(\"\\n🔄 SMOTE BALANCING:\")\n",
    "print(\"   Before SMOTE:\")\n",
    "for i, count in enumerate(train_dist_before):\n",
    "    print(f\"     {label_encoder.classes_[i]}: {count} samples\")\n",
    "print(\"   After SMOTE:\")\n",
    "for i, count in enumerate(train_dist_after):\n",
    "    print(f\"     {label_encoder.classes_[i]}: {count} samples\")\n",
    "\n",
    "print(\"\\n🔍 GRIDSEARCH CONFIGURATION:\")\n",
    "print(f\"   Total parameter combinations tested: {len(results_df)}\")\n",
    "print(f\"   Cross-validation folds: 5\")\n",
    "print(f\"   Search time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\n📈 PERFORMANCE RESULTS:\")\n",
    "print(f\"   KNN Murni: {accuracy_murni:.4f} ({accuracy_murni*100:.2f}%)\")\n",
    "print(f\"   KNN + SMOTE: {accuracy_smote_only:.4f} ({accuracy_smote_only*100:.2f}%)\")\n",
    "print(f\"   SMOTE + GridSearch + KNN: {grid_smote_accuracy:.4f} ({grid_smote_accuracy*100:.2f}%)\")\n",
    "print(f\"   Final improvement: {(grid_smote_accuracy - accuracy_murni)*100:+.2f} percentage points\")\n",
    "\n",
    "print(\"\\n⚙️ OPTIMAL HYPERPARAMETERS (AFTER GridSearch):\")\n",
    "for param, value in grid_search_smote.best_params_.items():\n",
    "    param_name = param.replace('knn__', '')\n",
    "    print(f\"   {param_name}: {value}\")\n",
    "\n",
    "print(\"\\n🎯 KEY FINDINGS:\")\n",
    "optimal_k = grid_search_smote.best_params_['knn__n_neighbors']\n",
    "print(f\"   • Optimal k value dengan SMOTE: {optimal_k}\")\n",
    "print(f\"   • SMOTE effect: {(accuracy_smote_only - accuracy_murni)*100:+.2f} pp improvement\")\n",
    "print(f\"   • GridSearch effect: {(grid_smote_accuracy - accuracy_smote_only)*100:+.2f} pp additional improvement\")\n",
    "print(f\"   • Combined effect: {(grid_smote_accuracy - accuracy_murni)*100:+.2f} pp total improvement\")\n",
    "\n",
    "print(\"\\n✅ CONCLUSION:\")\n",
    "if grid_smote_accuracy > max(accuracy_murni, accuracy_smote_only):\n",
    "    print(\"   SMOTE + GridSearch + KNN memberikan performa terbaik!\")\n",
    "    print(\"   Kombinasi balancing data dan hyperparameter tuning efektif.\")\n",
    "else:\n",
    "    print(\"   Perlu analisis lebih lanjut untuk optimasi yang lebih baik.\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35dd5d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**SMOTE + GridSearch + KNN Results**\n",
    "\n",
    "### 🔄 SMOTE Analysis:\n",
    "- **Data before SMOTE**: Distribusi kelas original dengan ketidakseimbangan\n",
    "- **Data after SMOTE**: Distribusi kelas yang seimbang setelah synthetic sampling\n",
    "- **Increase per class**: Jumlah sampel sintetis yang ditambahkan\n",
    "\n",
    "### ⚙️ GridSearch Optimization:\n",
    "- **Before GridSearch**: Hyperparameter default dengan SMOTE\n",
    "- **After GridSearch**: Hyperparameter optimal hasil comprehensive search\n",
    "- **Best combination**: SMOTE + optimized KNN parameters\n",
    "\n",
    "### 📊 Performance Comparison:\n",
    "- **K optimal**: Nilai k terbaik untuk SMOTE + GridSearch + KNN\n",
    "- **Improvement analysis**: Efek individual dan kombinasi dari SMOTE dan GridSearch\n",
    "- **Best approach**: Perbandingan dengan KNN murni dan KNN+SMOTE\n",
    "\n",
    "### 🎯 Key Insights:\n",
    "- Kombinasi SMOTE dan GridSearch memberikan optimasi maksimal\n",
    "- Balancing data dan hyperparameter tuning saling melengkapi\n",
    "- Model final merupakan hasil optimasi dua tahap yang komprehensif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
