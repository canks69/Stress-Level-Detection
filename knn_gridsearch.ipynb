{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638f03ce",
   "metadata": {},
   "source": [
    "# KNN Optimum dengan GridSearch - Stress Level Detection\n",
    "\n",
    "Implementasi KNN dengan optimasi hyperparameter menggunakan GridSearchCV untuk klasifikasi tingkat stress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade imbalanced-learn\n",
    "!pip install --upgrade scikit-learn\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "\n",
    "print(\"✅ Library berhasil diimport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b11f7e5",
   "metadata": {},
   "source": [
    "## 1. Data Loading dan Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = './dataset/fix dataset 1031.csv'\n",
    "\n",
    "# Read CSV with semicolon as separator and handle mixed decimal separators\n",
    "df = pd.read_csv(FILE_PATH, sep=';', decimal='.')\n",
    "dataset = df.copy()\n",
    "\n",
    "# Tampilkan Semua row pada kolom pertama yang memiliki nilai NaN\n",
    "print(\"📊 DATASET INFORMATION:\")\n",
    "print(\"Jumlah baris yang memiliki nilai NaN pada kolom pertama:\", dataset[dataset.columns[0]].isna().sum())\n",
    "\n",
    "# Bersihkan data dengan menghapus baris yang memiliki nilai NaN pada kolom pertama\n",
    "dataset = dataset.dropna(subset=[dataset.columns[0]])\n",
    "\n",
    "print(\"Dataset shape:\", dataset.shape)\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in Sleep Disorder with 'Normal'\n",
    "dataset['Sleep Disorder'] = dataset['Sleep Disorder'].fillna('Normal')\n",
    "\n",
    "# Split Blood Pressure column\n",
    "if 'Blood Pressure' in dataset.columns:\n",
    "    dataset[['Systolic', 'Diastolic']] = dataset['Blood Pressure'].str.split('/', expand=True)\n",
    "    dataset['Systolic'] = pd.to_numeric(dataset['Systolic'], errors='coerce')\n",
    "    dataset['Diastolic'] = pd.to_numeric(dataset['Diastolic'], errors='coerce')\n",
    "    dataset = dataset.drop('Blood Pressure', axis=1)\n",
    "\n",
    "# Clean numeric columns\n",
    "kolom_numerik = [\"Sleep Duration\", \"Heart Rate\", \"Daily Steps\", \"Systolic\", \"Diastolic\"]\n",
    "for col in kolom_numerik:\n",
    "    if col in dataset.columns:\n",
    "        dataset[col] = dataset[col].apply(lambda x: str(x).replace(',', '.') if isinstance(x, str) else x)\n",
    "        dataset[col] = pd.to_numeric(dataset[col], errors='coerce')\n",
    "\n",
    "print(\"✅ Data preprocessing selesai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac6357",
   "metadata": {},
   "source": [
    "## 2. Target Encoding dan Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c325c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for target\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(dataset['Sleep Disorder'])\n",
    "\n",
    "print(\"Target classes:\", label_encoder.classes_)\n",
    "print(\"Encoded values:\", np.unique(target_encoded))\n",
    "\n",
    "# Show class distribution\n",
    "print(\"\\n=== DISTRIBUSI KELAS ====\")\n",
    "class_counts = pd.Series(target_encoded).value_counts().sort_index()\n",
    "for i, count in enumerate(class_counts):\n",
    "    print(f\"{label_encoder.classes_[i]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "feature_columns = [\"Gender\", \"Age\", \"Occupation\", \"Sleep Duration\", \"Quality of Sleep\", \n",
    "                  \"Physical Activity Level\", \"Stress Level\", \"BMI Category\", \"Systolic\", \"Diastolic\"]\n",
    "\n",
    "# Filter only existing columns\n",
    "available_features = [col for col in feature_columns if col in dataset.columns]\n",
    "features = dataset[available_features]\n",
    "\n",
    "print(\"Selected features:\", available_features)\n",
    "print(\"Features shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb1364e",
   "metadata": {},
   "source": [
    "## 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target_encoded, test_size=0.2, random_state=42, stratify=target_encoded\n",
    ")\n",
    "\n",
    "print(\"=== DATA SPLIT ====\")\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "print(\"\\nDistribusi y_train:\")\n",
    "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
    "for i, count in enumerate(train_dist):\n",
    "    print(f\"{label_encoder.classes_[i]}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c47a06e",
   "metadata": {},
   "source": [
    "## 4. Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical features\n",
    "numerical_features = [col for col in available_features if features[col].dtype in ['int64', 'float64']]\n",
    "categorical_features = [col for col in available_features if features[col].dtype == 'object']\n",
    "\n",
    "print(\"Numerical features:\", numerical_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Create preprocessors\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "print(\"✅ Preprocessor pipeline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a620d3",
   "metadata": {},
   "source": [
    "## 5. Baseline Model (Before GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de029ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline KNN pipeline (default parameters)\n",
    "baseline_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Train baseline model\n",
    "print(\"Training baseline model...\")\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "baseline_pred = baseline_pipeline.predict(X_test)\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
    "\n",
    "print(\"=== BASELINE MODEL (BEFORE GridSearch) ====\")\n",
    "print(\"Default hyperparameters:\")\n",
    "knn_params = baseline_pipeline.named_steps['knn'].get_params()\n",
    "important_params = ['n_neighbors', 'weights', 'algorithm', 'metric', 'p']\n",
    "for param in important_params:\n",
    "    if param in knn_params:\n",
    "        print(f\"  {param}: {knn_params[param]}\")\n",
    "\n",
    "print(f\"\\nBaseline accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e41880",
   "metadata": {},
   "source": [
    "## 6. GridSearchCV untuk Optimasi Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8dac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'knn__p': [1, 2]  # Only relevant for minkowski metric\n",
    "}\n",
    "\n",
    "print(\"Parameter grid for GridSearch:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "print(f\"\\nTotal combinations to test: {np.prod([len(v) for v in param_grid.values()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50428ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for GridSearch\n",
    "grid_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Perform GridSearchCV\n",
    "print(\"Starting GridSearchCV...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    grid_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n✅ GridSearchCV completed in {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b9702",
   "metadata": {},
   "source": [
    "## 7. GridSearch Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display GridSearch results\n",
    "print(\"=== GRIDSEARCH RESULTS ====\")\n",
    "print(\"\\nBest parameters found:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest cross-validation score: {grid_search.best_score_:.4f} ({grid_search.best_score_*100:.2f}%)\")\n",
    "\n",
    "# Test the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_grid = best_model.predict(X_test)\n",
    "grid_accuracy = accuracy_score(y_test, y_pred_grid)\n",
    "\n",
    "print(f\"Test set accuracy with best model: {grid_accuracy:.4f} ({grid_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ad332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Before vs After GridSearch\n",
    "print(\"=== COMPARISON: BEFORE vs AFTER GridSearch ====\")\n",
    "print(\"\\nBEFORE GridSearch (default parameters):\")\n",
    "print(f\"  n_neighbors: 5\")\n",
    "print(f\"  weights: uniform\")\n",
    "print(f\"  algorithm: auto\")\n",
    "print(f\"  metric: minkowski\")\n",
    "print(f\"  p: 2\")\n",
    "print(f\"  Accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nAFTER GridSearch (optimized parameters):\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    param_name = param.replace('knn__', '')\n",
    "    print(f\"  {param_name}: {value}\")\n",
    "print(f\"  Accuracy: {grid_accuracy:.4f} ({grid_accuracy*100:.2f}%)\")\n",
    "\n",
    "improvement = grid_accuracy - baseline_accuracy\n",
    "print(f\"\\nImprovement: {improvement:.4f} ({improvement*100:.2f} percentage points)\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"✅ GridSearch improved the model performance!\")\n",
    "elif improvement == 0:\n",
    "    print(\"➖ No improvement from GridSearch\")\n",
    "else:\n",
    "    print(\"⚠️ GridSearch resulted in lower performance (may indicate overfitting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711e99de",
   "metadata": {},
   "source": [
    "## 8. Detailed Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592307c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"=== DETAILED PERFORMANCE ANALYSIS ====\")\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred_grid, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4aac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_grid = confusion_matrix(y_test, y_pred_grid)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_grid, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix - KNN with GridSearch\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8255623c",
   "metadata": {},
   "source": [
    "## 9. Top 10 Best Parameter Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edb7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 10 parameter combinations\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "top_10 = results_df.nlargest(10, 'mean_test_score')[['mean_test_score', 'std_test_score', 'params']]\n",
    "\n",
    "print(\"=== TOP 10 PARAMETER COMBINATIONS ====\")\n",
    "for i, (idx, row) in enumerate(top_10.iterrows(), 1):\n",
    "    print(f\"\\n{i}. Score: {row['mean_test_score']:.4f} (±{row['std_test_score']:.4f})\")\n",
    "    print(f\"   Parameters: {row['params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214fb0e",
   "metadata": {},
   "source": [
    "## 10. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the effect of n_neighbors parameter\n",
    "k_values = param_grid['knn__n_neighbors']\n",
    "k_scores = []\n",
    "\n",
    "# Filter results for the best other parameters but varying k\n",
    "best_params_except_k = {k: v for k, v in grid_search.best_params_.items() if k != 'knn__n_neighbors'}\n",
    "\n",
    "for k in k_values:\n",
    "    # Find results with this k and best other parameters\n",
    "    matching_rows = results_df[\n",
    "        (results_df['param_knn__n_neighbors'] == k) &\n",
    "        (results_df['param_knn__weights'] == best_params_except_k.get('knn__weights')) &\n",
    "        (results_df['param_knn__algorithm'] == best_params_except_k.get('knn__algorithm')) &\n",
    "        (results_df['param_knn__metric'] == best_params_except_k.get('knn__metric')) &\n",
    "        (results_df['param_knn__p'] == best_params_except_k.get('knn__p'))\n",
    "    ]\n",
    "    \n",
    "    if not matching_rows.empty:\n",
    "        k_scores.append(matching_rows['mean_test_score'].iloc[0])\n",
    "    else:\n",
    "        k_scores.append(0)\n",
    "\n",
    "# Plot k vs accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, k_scores, marker='o', linewidth=2, markersize=6)\n",
    "best_k = grid_search.best_params_['knn__n_neighbors']\n",
    "plt.axvline(x=best_k, color='red', linestyle='--', alpha=0.7, label=f'Best k={best_k}')\n",
    "plt.title('Cross-Validation Accuracy vs. Number of Neighbors (k)')\n",
    "plt.xlabel('k (Number of Neighbors)')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.xticks(k_values)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs optimized model performance\n",
    "models = ['Baseline KNN', 'Optimized KNN (GridSearch)']\n",
    "accuracies = [baseline_accuracy, grid_accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(models, accuracies, color=['lightblue', 'darkblue'], alpha=0.7)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{acc:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc7d79",
   "metadata": {},
   "source": [
    "## 11. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL SUMMARY - KNN OPTIMIZATION WITH GRIDSEARCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n📊 DATASET INFORMATION:\")\n",
    "print(f\"   Total samples: {len(dataset)}\")\n",
    "print(f\"   Features used: {len(available_features)}\")\n",
    "print(f\"   Classes: {len(label_encoder.classes_)} ({', '.join(label_encoder.classes_)})\")\n",
    "\n",
    "print(\"\\n🔍 GRIDSEARCH CONFIGURATION:\")\n",
    "print(f\"   Total parameter combinations tested: {len(results_df)}\")\n",
    "print(f\"   Cross-validation folds: 5\")\n",
    "print(f\"   Search time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\n📈 PERFORMANCE RESULTS:\")\n",
    "print(f\"   Baseline accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
    "print(f\"   Optimized accuracy: {grid_accuracy:.4f} ({grid_accuracy*100:.2f}%)\")\n",
    "print(f\"   Improvement: {improvement*100:+.2f} percentage points\")\n",
    "\n",
    "print(\"\\n⚙️ OPTIMAL HYPERPARAMETERS:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    param_name = param.replace('knn__', '')\n",
    "    print(f\"   {param_name}: {value}\")\n",
    "\n",
    "print(\"\\n🎯 KEY FINDINGS:\")\n",
    "optimal_k = grid_search.best_params_['knn__n_neighbors']\n",
    "print(f\"   • Optimal k value: {optimal_k}\")\n",
    "print(f\"   • Best weights: {grid_search.best_params_['knn__weights']}\")\n",
    "print(f\"   • Best algorithm: {grid_search.best_params_['knn__algorithm']}\")\n",
    "print(f\"   • Best metric: {grid_search.best_params_['knn__metric']}\")\n",
    "\n",
    "if improvement > 0.01:\n",
    "    print(\"\\n✅ GridSearch significantly improved model performance!\")\n",
    "elif improvement > 0:\n",
    "    print(\"\\n✅ GridSearch slightly improved model performance.\")\n",
    "else:\n",
    "    print(\"\\n➖ GridSearch did not improve model performance.\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4edb8a0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**KNN Optimum dengan GridSearch Results:**\n",
    "- **Before GridSearch**: Default hyperparameters and their performance\n",
    "- **After GridSearch**: Optimized hyperparameters found through systematic search\n",
    "- **Best k value**: Determined through comprehensive testing of multiple parameter combinations\n",
    "- **Performance improvement**: Quantified improvement over baseline model\n",
    "- **Optimal hyperparameters**: Complete set of best parameters for maximum performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
